%==============================================================================
% PREAMBLE
%==============================================================================
\documentclass[mathserif, xcolor=dvipsnames]{beamer}
% \usepackage{helvet}
\usepackage[T1]{fontenc}
\usepackage{amsmath, amsfonts,amsthm}
\usepackage{url}
\usepackage{listings}
\usepackage{color}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\lstset{basicstyle=\footnotesize,language=Python,commentstyle=\color{mygray}}

\usetheme[height=10mm]{Rochester}
\usecolortheme[named=MidnightBlue]{structure}
\setbeamertemplate{navigation symbols}{}

\title{Theano primer}
\author{Vincent Dumoulin}
\date{January 15, 2015}

%==============================================================================
% BODY
%==============================================================================
\begin{document}

%------------------------------------------------------------------------------
% TITLE
%------------------------------------------------------------------------------
\begin{frame}[plain]
    \titlepage
\end{frame}

%------------------------------------------------------------------------------
% What is Theano?
%------------------------------------------------------------------------------
\begin{frame}
    \frametitle{What is Theano?}
    \begin{itemize}
    \item{From Theano's online documentation:
        \begin{quote}
            Theano is a Python library that allows you to define, optimize,
            and evaluate mathematical expressions involving multi-dimensional
            arrays efficiently.
        \end{quote}}
    \item{Does \emph{symbolic} computation \textbf{and} differentiation
          (\emph{i.e.} the end result of differentiation is itself a symbolic
          expression)}
    \item{Very similar to numpy with respect to its interface}
    \item{Allows doing numerical computation in a high-level language (Python)
          while still retaining the speed of low-level languages (like C)}
    \item{Allows the generation of efficient CPU and GPU code transparently}
    \end{itemize}
\end{frame}

%------------------------------------------------------------------------------
% Typical Theano workflow
%------------------------------------------------------------------------------
\begin{frame}
    \frametitle{Typical Theano workflow}
    \begin{enumerate}\addtolength{\itemsep}{1.0\baselineskip}
        \item{Instantiate symbolic variables}
        \item{Build a computation graph out of those variables}
        \item{Compile a function with the symbolic variables as input and the
              output of the computation graph as output}
        \item{Call the compiled function with numerical inputs}
    \end{enumerate}

    You can manipulate Theano symbolic variables in the same way you'd
    manipulate numpy arrays.
\end{frame}

%------------------------------------------------------------------------------
% Theano vs. numpy
%------------------------------------------------------------------------------
\begin{frame}
    \frametitle{Theano vs. numpy}
    \begin{itemize}\addtolength{\itemsep}{1.0\baselineskip}
        \item{Theano interface is \emph{very} similar to numpy interface}
        \item{Complete reference to most of Theano's interface can be found
              here: \linebreak
 \url{http://deeplearning.net/software/theano/library/tensor/basic.html}}
        \item{numpy arrays are automatically converted to constant symbolic
              variables when used inside a computation graph}
    \end{itemize}
\end{frame}

%------------------------------------------------------------------------------
% Types of symbolic variables
%------------------------------------------------------------------------------
\begin{frame}
    \frametitle{Types of symbolic variables}
    \begin{description}\addtolength{\itemsep}{1.0\baselineskip}
        \item[TensorVariable]{Its value is unspecified at graph creation and
                              can change from one call of the compiled function
                              to another (\emph{e.g.} $x$ and $y$ in
                              $y = 3x - 2$)}
        \item[TensorConstant]{Its value is specified at graph creation and
                              does \textbf{not} change from one call of the
                              compiled funtion to another (\emph{e.g.} $3$ and
                              $-2$ in $y = 3x - 2$)}
        \item[TensorSharedVariable]{Its value is specified at graph creation
                                    but is bound to change from one call of the
                                    compiled function to another (\emph{e.g.}
                                    $a$ and $b$ in $y = ax + b$ in a regression
                                    setting where some $x$ and $y$ pairs have
                                    been observed)}
    \end{description}
\end{frame}

%------------------------------------------------------------------------------
% Starting example: simple algebra
%------------------------------------------------------------------------------
\begin{frame}[fragile]
    \frametitle{Starting example: simple algebra}
\begin{lstlisting}
import theano
import theano.tensor as T

# 1. Instantiate symbolic variables
x = T.vector(name='x')
y = T.vector(name='y')

# 2. Build a computation graph
z = x + y

# 3. Compile a callable function
f = theano.function(inputs=[x, y], outputs=z)

# 4. Call the function using numerical inputs
print f([1, 2], [3, 4])
\end{lstlisting}
\end{frame}

%------------------------------------------------------------------------------
% Differentiation
%------------------------------------------------------------------------------
\begin{frame}[fragile]
    \frametitle{Going further: gradient computation}
\begin{lstlisting}
import theano
import theano.tensor as T

# 1. Instantiate symbolic variables
x = T.vector(name='x')

# 2. Build a computation graph
z = (x ** 2).sum()
d_z_d_x = T.grad(z, x)

# 3. Compile a callable function
f = theano.function(inputs=[x], outputs=d_z_d_x)

# 4. Call the function using numerical inputs
print f([1, 2])
\end{lstlisting}
\end{frame}

%------------------------------------------------------------------------------
% Summary
%------------------------------------------------------------------------------
\begin{frame}[fragile]
    \frametitle{Putting it together: linear regression}
\begin{lstlisting}
import theano
import theano.tensor as T

x = T.scalar(name='x')
t = T.scalar(name='t')
a = theano.shared(-1.0, name='a')
b = theano.shared(0.0, name='b')

y = a * x + b
mse = (y - t) ** 2
grad_a, grad_b = T.grad(mse, [a, b])

f = theano.function(inputs=[x, t], outputs=mse,
                    updates={a: a - 0.01 * grad_a,
                             b: b - 0.01 * grad_b})

print [f(1, 5)) for i in xrange(10)]
\end{lstlisting}
\end{frame}

%------------------------------------------------------------------------------
% For more information
%------------------------------------------------------------------------------
\begin{frame}
    \frametitle{Going further}
    For more information, have a look at the online Theano tutorial:
    \begin{center}
        \url{http://deeplearning.net/software/theano/tutorial/index.html\#tutorial}
    \end{center}
\end{frame}

\end{document}
